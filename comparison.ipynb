{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import starmap, product\n",
    "from math import log, exp\n",
    "from pathlib import Path\n",
    "from random import gauss\n",
    "from typing import Tuple, NoReturn\n",
    "\n",
    "from X import X\n",
    "from algebra import Matrix, Vector, vector, Scalar, mult_mv, diff_vv, sum_vv, mult_vs\n",
    "from model import Model\n",
    "from stop_conditions import StopConditions\n",
    "\n",
    "\n",
    "def load(filepath: Path) -> Tuple[Matrix, Vector]:\n",
    "    assert filepath.exists() and filepath.is_file()\n",
    "\n",
    "    with filepath.open() as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    samples = map(lambda l: l.split(), lines)\n",
    "    samples = (tuple(map(lambda v: int(v), s)) for s in samples)\n",
    "    samples = ((s[:-1], s[-1]) for s in samples)\n",
    "\n",
    "    return tuple(zip(*samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "x,y = load(Path('breast-cancer.data'))\n",
    "x = X(vector(map(lambda xi: vector(map(lambda xij: xij-1, xi)), x)))\n",
    "y = vector(map(lambda r: 0 if r == 2 else 1, y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_error(pred: Vector, y: Vector) -> float:\n",
    "    assert len(pred) == len(y)\n",
    "    same = sum(starmap(lambda a, b: a == b, zip(pred, y)))\n",
    "    return 1. - (float(same) / len(y))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class NaiveBayes(Model):\n",
    "    def __init__(self, nfeatures: int, domain_size: int):\n",
    "        self._domain_size, self._nfeatures = domain_size, nfeatures\n",
    "        self._py = 0.\n",
    "        self._pi = [[[0.] * self._domain_size for _ in range(self._nfeatures)],\n",
    "                    [[0.] * self._domain_size for _ in range(self._nfeatures)]]\n",
    "\n",
    "    def train(self, x: X, y: Vector) -> NoReturn:\n",
    "        assert x.nfeatures() == self._nfeatures\n",
    "\n",
    "        m = len(y)\n",
    "        ones = sum(y)\n",
    "        zeros = m - ones\n",
    "\n",
    "        self._py = (1. + ones) / (m + 2.)\n",
    "\n",
    "        counters = [[[0] * self._domain_size for _ in range(self._nfeatures)],\n",
    "                    [[0] * self._domain_size for _ in range(self._nfeatures)]]\n",
    "\n",
    "        for xi, yi in zip(x.by_sample(), y):\n",
    "            for j, xij in enumerate(xi):\n",
    "                counters[yi][j][xij] += 1\n",
    "\n",
    "        for y_val, feature, k in product([0, 1], range(self._nfeatures), range(self._domain_size)):\n",
    "            denominator = self._domain_size + y_val * ones + (1 - y_val) * zeros\n",
    "            self._pi[y_val][feature][k] = (1 + counters[y_val][feature][k]) / denominator\n",
    "\n",
    "    def _predict_one(self, x: Vector) -> Scalar:\n",
    "        assert len(x) == self._nfeatures\n",
    "        p0 = log(1. - self._py) + self._likelihood(x, 0)\n",
    "        p1 = log(self._py) + self._likelihood(x, 1)\n",
    "        return 0 if p0 >= p1 else 1\n",
    "\n",
    "    def _likelihood(self, x: Vector, y_val: Scalar):\n",
    "        assert y_val in [0, 1]\n",
    "        return sum(map(lambda k: log(self._pi[y_val][k][x[k]]), range(len(x))))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "STDEV = 1.\n",
    "STOP_CONDITION = StopConditions(0.000001, None, 5000)\n",
    "GRADIENT_STEP = 0.0001\n",
    "\n",
    "\n",
    "class LogisticRegression(Model):\n",
    "    def __init__(self):\n",
    "        self._theta = None\n",
    "\n",
    "    def train(self, x: X, y: Vector) -> NoReturn:\n",
    "        x = x.append_ones()\n",
    "\n",
    "        theta = vector(map(lambda _: gauss(0., STDEV), range(x.nfeatures())))\n",
    "\n",
    "        stop_condition, stop = STOP_CONDITION, False\n",
    "        while not stop:\n",
    "            prediction = self._compute_prob(x, theta)\n",
    "            diff = diff_vv(y, prediction)\n",
    "            gradient = mult_mv(x.by_feature(), diff)\n",
    "\n",
    "            theta = sum_vv(theta, mult_vs(gradient, GRADIENT_STEP))\n",
    "            error = compute_error(self._decide(prediction), y)\n",
    "\n",
    "            stop_condition, stop = stop_condition.update(gradient, error)\n",
    "            # print(error)\n",
    "\n",
    "        self._theta = theta\n",
    "\n",
    "    @staticmethod\n",
    "    def _compute_prob(x: X, theta: Vector) -> Vector:\n",
    "        multiplied = mult_mv(x.by_sample(), theta)\n",
    "        return vector(map(lambda m: 1. / (1. + exp(-m)), multiplied))\n",
    "\n",
    "    @staticmethod\n",
    "    def _decide(ps: Vector) -> Vector:\n",
    "        return vector(map(lambda p: 0 if p <= 0.5 else 1, ps))\n",
    "\n",
    "    def predict(self, x: X) -> Vector:\n",
    "        assert self._theta is not None, \"Model not trained yet\"\n",
    "        x = x.append_ones()\n",
    "        probs = self._compute_prob(x, self._theta)\n",
    "        return vector(map(lambda p: 0 if p <= 0.5 else 1, probs))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0.02342606149341142"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = NaiveBayes(9,10)\n",
    "b.train(x, y)\n",
    "compute_error(b.predict(x), y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.029282576866764276"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.train(x, y)\n",
    "compute_error(lr.predict(x), y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}